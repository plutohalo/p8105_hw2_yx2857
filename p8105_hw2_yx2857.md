p8105_hw2_yx2857
================

**Problem 1**

``` r
# Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or case_match function may be useful)

# Read the data

subway <- read_csv(
    file = "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |> 
  janitor::clean_names() |> 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
#Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?
```

This cleaned dataset contains 1868 rows and 20 columns. The variables
include line, station name, station latitude, station longitude, routes
served, entrance type, and ADA compliance. The data cleaning steps
include reading the data, cleaning the column names, and checking the
data structure, changing the variable class to character of variables
`route8` through `route11`. The data is not tidy, majorly because the
`route` variables are stored in a wide format rather than a long format.
The current wide format will cause problems when we want to analyze
specific routes.

``` r
# Answer the following questions using these data:
#
# How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox); the distinct function may be useful here.
subway_stations <- subway |> 
  distinct(station_name, line)

# How many stations are ADA compliant?
ada_stations <- subway |> 
  filter(ada == TRUE) |> 
  distinct(station_name, line)
# What proportion of station entrances / exits without vending allow entrance?
prop_no_vending_entry <- subway |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
# Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train?
subway_stations_A <- subway |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()
# Of the stations that serve the A train, how many are ADA compliant
subway_stations_A_ada <- subway |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

There are 465 distinct stations in the dataset.  
There are 84 ADA compliant stations in the dataset.  
The proportion of station entrances / exits without vending that allow
entrance is 0.38.  
There are 60 distinct stations that serve the A train.  
There are 17 ADA compliant stations that serve the A train.

**Problem 2**

``` r
# This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website.
# 
# Read and clean the Mr. Trash Wheel sheet:


# 1 specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
# 2 use reasonable variable names
# 3 omit rows that do not include dumpster-specific data
# 4 round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)
# 5 Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine this with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to both datasets before combining.

mr_trash_wheel <- read_excel(
    path = "data/202409 Trash Wheel Collection Data.xlsx",
    sheet = "Mr. Trash Wheel",
    skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  select(where(function(x) any(!is.na(x))))|> 
  mutate(
    sports_balls = as.integer(round(sports_balls))
  ) |> mutate(trash_wheel = "Mr. Trash") |>
  mutate(year = as.numeric(year))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
prof_trash_wheel <- read_excel(
    path = "data/202409 Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel",
    skip = 1) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(trash_wheel = "Professor")

gwynnda <- read_excel(
    path = "data/202409 Trash Wheel Collection Data.xlsx",
    sheet = "Gwynnda Trash Wheel",
    skip = 1) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(trash_wheel = "Gwynnda")

trash_wheels <- bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda)

# Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in June of 2022?
```

The trash wheel dataset, consisting data from Mr. Trash, Professor, and
Gwynnda wheels, contains 1033 observations and 15 variables. The key
variables include `year`, `month`, `dumpster`, trash
weight(`weight_tons`), trash volume (`volume_cubic_yards`),
`plastic_bottles`, `cigarette_butts`, and `trash_wheel`. The total
weight of trash collected by Professor Trash Wheel is 246.74 tons. The
total number of cigarette butts collected by Gwynnda in June of 2022 is
1.812^{4}.  
It seems like the variable `homes_powered` is stored in the excel
spreadsheet as a formula, calculating the number of homes powered by the
collected trash weight, which is the `weight_tons` \*500/30. Although
some rows of this variable was not provided (as missing), or imput with
a number (like 0) rather than calculing as above, I decided to keep the
original data as it is due to the lack of related information.

**Problem 3**

``` r
# This problem uses data on elements of the Great British Bake Off. The show has been running for 10 seasons; in each episode, contestants compete in signature challenges, technical challenges, and a showstopper. At the end of an episode the winner is crowned “Star Baker” (and winner in the last episode of a season), and a loser is eliminated.
# Information about individual bakers, their bakes, and their performance is included in bakers.csv, bakes.csv, and results.csv. 


# In the first part of this problem, your goal is to create a single, well-organized dataset with all the information contained in these data files. To that end: import, clean, tidy, and otherwise wrangle each of these datasets; check for completeness and correctness across datasets (e.g. by viewing individual datasets and using anti_join); merge to create a single, final dataset; and organize this so that variables and observations are in meaningful orders. Export the result as a CSV in the directory containing the original datasets.

bakers <- read_csv("data/gbb_datasets/bakers.csv") |> 
  janitor::clean_names() |> 
  separate(baker_name, into = c("baker", "last_name"), sep = " ")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes <- read_csv("data/gbb_datasets/bakes.csv") |>
  janitor::clean_names() |>
  mutate(baker = ifelse(baker == '"Jo"', "Johanne", baker))
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results <- read_csv("data/gbb_datasets/results.csv",
                    skip = 2) |>
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# Merge the datasets

gbb_data <- results |> 
  left_join(bakes, by = c("baker", "series", "episode")) |> 
  left_join(bakers, by = c("baker", "series"))


# Export the result as a CSV in the directory containing the original datasets.
write_csv(gbb_data, "data/gbb_datasets/gbb_data.csv")


#Describe your data cleaning process, including any questions you have or choices you made. Briefly discuss the final dataset.
```

The data cleaning process involved reading the data, cleaning the column
names, and checking the data structure. The `bakers` dataset was
separated into first and last names. The `bakes` and `results` datasets
were read and cleaned. The `results` dataset was joined with the `bakes`
dataset and the `bakers` dataset to create a single dataset `gbb_data`.
The final dataset contains information about individual bakers, their
bakes, and their performance. The dataset is tidy, with as completed
information as possible. Discussing from the structure of the relational
database, the parent table is `baker` and the child tables are `bakes`
and `results`. The `baker` table is connected to the `bakes` and
`results` tables through the pirmary key, `baker` variable. The `bakes`
and `results` tables are connected through the composite keys, `bake`,
`series` and `episode` variables.

Along the cleaning, I notice a baker named “Jo” in season 2, episode 3,
who has no corresponding record in the `bakers` dataset, and the
`bakers` table suggest there is only one baker named “Johanne” in this
season. I googled it, and I found that “Jo” is a nickname for “Johanne”,
Johanne Wheatley. So I decided to merge the two names into one by
replace “Jo” in `bakes` with her real name “Johanne” to match with other
datasets.

The final data, `gbb_data`, contains 1136 observations and 11 variables.
The key variables include `series`, `episode`, `baker`, `technical`,
`result`, `signature_bake`, `showstopper`, `last_name`, `baker_age`,
`baker_occupation`, and `hometown`. The dataset includes the information
of bakers and their performance in the 10 series of Great British Bake
Off.

``` r
#Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10. Comment on this table – were there any predictable overall winners? Any surprises?
gbb_data |>
  filter(series >= 5) |>
  filter(result == "STAR BAKER" | result == "WINNER") |>
  select(series, episode, baker, result) |>
  pivot_wider(names_from = result, values_from = baker) |>
  select(series, episode, `STAR BAKER`, WINNER) |>
  arrange(series, episode) |>
  #replace NA with ""
  mutate(across(everything(), ~ replace_na(., ""))) |>
  knitr::kable()
```

| series | episode | STAR BAKER | WINNER  |
|-------:|--------:|:-----------|:--------|
|      5 |       1 | Nancy      |         |
|      5 |       2 | Richard    |         |
|      5 |       3 | Luis       |         |
|      5 |       4 | Richard    |         |
|      5 |       5 | Kate       |         |
|      5 |       6 | Chetna     |         |
|      5 |       7 | Richard    |         |
|      5 |       8 | Richard    |         |
|      5 |       9 | Richard    |         |
|      5 |      10 |            | Nancy   |
|      6 |       1 | Marie      |         |
|      6 |       2 | Ian        |         |
|      6 |       3 | Ian        |         |
|      6 |       4 | Ian        |         |
|      6 |       5 | Nadiya     |         |
|      6 |       6 | Mat        |         |
|      6 |       7 | Tamal      |         |
|      6 |       8 | Nadiya     |         |
|      6 |       9 | Nadiya     |         |
|      6 |      10 |            | Nadiya  |
|      7 |       1 | Jane       |         |
|      7 |       2 | Candice    |         |
|      7 |       3 | Tom        |         |
|      7 |       4 | Benjamina  |         |
|      7 |       5 | Candice    |         |
|      7 |       6 | Tom        |         |
|      7 |       7 | Andrew     |         |
|      7 |       8 | Candice    |         |
|      7 |       9 | Andrew     |         |
|      7 |      10 |            | Candice |
|      8 |       1 | Steven     |         |
|      8 |       2 | Steven     |         |
|      8 |       3 | Julia      |         |
|      8 |       4 | Kate       |         |
|      8 |       5 | Sophie     |         |
|      8 |       6 | Liam       |         |
|      8 |       7 | Steven     |         |
|      8 |       8 | Stacey     |         |
|      8 |       9 | Sophie     |         |
|      8 |      10 |            | Sophie  |
|      9 |       1 | Manon      |         |
|      9 |       2 | Rahul      |         |
|      9 |       3 | Rahul      |         |
|      9 |       4 | Dan        |         |
|      9 |       5 | Kim-Joy    |         |
|      9 |       6 | Briony     |         |
|      9 |       7 | Kim-Joy    |         |
|      9 |       8 | Ruby       |         |
|      9 |       9 | Ruby       |         |
|      9 |      10 |            | Rahul   |
|     10 |       1 | Michelle   |         |
|     10 |       2 | Alice      |         |
|     10 |       3 | Michael    |         |
|     10 |       4 | Steph      |         |
|     10 |       5 | Steph      |         |
|     10 |       6 | Steph      |         |
|     10 |       7 | Henry      |         |
|     10 |       8 | Steph      |         |
|     10 |       9 | Alice      |         |
|     10 |      10 |            | David   |

The table above shows the star baker or winner of each episode in
Seasons 5 through 10. There were no predictable overall winners, and
there were some surprises that the final winner might fail to win more
“Star Baker” titles than the peers in the season.

``` r
# Import, clean, tidy, and organize the viewership data in viewers.csv. Show the first 10 rows of this dataset. 
viewers <- read_csv("data/gbb_datasets/viewers.csv") |>
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
viewers |>
  head(10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
# What was the average viewership in Season 1? In Season 5?
```

The average viewership in Season 1 was 2.77. The average viewership in
Season 5 was 10.0393.
